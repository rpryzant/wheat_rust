"""
trains model on sequences of pixels 


=== USAGE:
python train.py sequences.npy
    ( where sequences.npy was generated by generate_dataset.py )
"""
from model import LSTM
import sys
import random
import numpy as np
from tqdm import tqdm
import matplotlib.pyplot as plt

def iter_batches(X, Y, batch_size):
    """ chop X and Y up into batches and yield 'em
    """
    for i in range(0, len(Y) - batch_size)[::batch_size]:
        yield X[i:i+batch_size], Y[i:i+batch_size]


def one_hot(v, num_classes=2):
    """ given a list of ints, replaces each element with
        its one-hot encoding
    """
    out = []
    for vi in v:
        x = [0] * num_classes
        x[vi] = 1
        out += [x]
    return out

def from_one_hot(v):
    """ reverses one-hot encodings
    """
    return np.argmax(v, axis=1)



def difference(X):
    """ replaces a list of vectors with a list of deltas between each neighbor
    """
    out = [ 
             [ seq[i] - seq[i-1] for i in range(1, len(seq)) ] \
             for seq in X
          ]
    return out


def accuracy(Y_hat, Y):
#    Y = from_one_hot(Y)   # reverse one-hot
    return sum(1 if x == y else 0 for (x, y) in zip(Y_hat, Y)) * 1.0 / len(Y)


def train_test_splits(X, Y, N, f):
    X_train = X[:N/f]
    Y_train = Y[:N/f]

    X_test = X[N/f:]
    Y_test = Y[N/f:]

    return X_train, one_hot(Y_train), X_test, one_hot(Y_test)


def train_val_test_splits(X, Y, N, f):
    X_train = X[:N/f]
    Y_train = Y[:N/f]

    X_tmp = X[N/f:]
    Y_tmp = Y[N/f:]
    
    X_val = X_tmp[:N/(f*2)]
    Y_val = Y_tmp[:N/(f*2)]

    X_test = X_tmp[N/(f*2):]
    Y_test = Y_tmp[N/(f*2):]

    return X_train, one_hot(Y_train), X_val, one_hot(Y_val), X_test, one_hot(Y_test)

'''
from datetime import date
def time_series(s, e):
    pix = []
    for p in pixel:
	if s <= p.date <=end:
	    pix.append(p)		
'''		





# read in dataset from generate_dataset.py
# structured as [ [label, [[day of year, pixel], ...] ], ... ]
dataset = np.load(sys.argv[1])
# load in model
model_path = None
if len(sys.argv) > 2:
    model_path = sys.argv[2]
# write model
model_out = None
if len(sys.argv) > 3:
    model_out = sys.argv[3]



# remove day of year information from X, and change ints to floats
dataset = [(label, [vec[1].real.astype(float) for vec in sequence]) \
               for [label, sequence] in dataset]
random.shuffle(dataset)       # and shuffle it
Y, X = zip(*dataset)                    # pull out data
#X = list(X)
#Y = list(Y)



# hyperparams
MAX_SEQ_LEN = max(len(x) for x in X) + 3  # give a little wiggle room 
NUM_CLASSES = 2                           # 0/1 for diseased or not
NUM_FEATURES = len(X[0][0])               # length of pixel vector
BATCH_SIZE = 16
N = len(Y)


# train/test splits
X = X[:100]
Y = Y[:100]
N = len(Y)

print X[0]
X = difference(X)
#X_train, Y_train, X_val, Y_val, X_test, Y_test = train_val_test_splits(X, Y, N, 8)
print X[0]
X_train, Y_train, X_val, Y_val = train_test_splits(X, Y, N, 8)
#print X_train[0]
#print Y_train[0]
#print X_val[0]
#print Y_val[0]

model = LSTM(num_classes=NUM_CLASSES,
             max_seq_len=MAX_SEQ_LEN,
             num_features=NUM_FEATURES,
             learning_rate=0.0003,
             hidden_units=64,
             model_path=model_path)

print 'epoch,mean_loss,train_acc,val_acc'

xaxis = []
yaxis = []

for epoch in range(500):
    epoch_loss = 0
    for x_batch, y_batch in iter_batches(X_train, Y_train, BATCH_SIZE):
        epoch_loss += model.train_on_batch(x_batch, y_batch)
    epoch_loss = epoch_loss * 1.0 / (N / BATCH_SIZE)
    print '%s,%s,%s,%s' % (
        epoch, epoch_loss, 
        accuracy(model.predict(X_train), from_one_hot(Y_train)), 
        accuracy(model.predict(X_val), from_one_hot(Y_val))
        )
    xaxis.append(epoch)
    yaxis.append(accuracy(model.predict(X_train), from_one_hot(Y_train)))


plt.plot(xaxis, yaxis)
plt.show()

#  TODO  - CLEAN THIS SHIT UP
print '=== BASELINE ACC'
Y_val = from_one_hot(Y_val)
N1 = np.sum(Y_val)
N0 = len(Y_val) - N1
print '\t random (freqs): %s' % (max(N0, N1) * 1.0 / (N0 + N1)) 
Y_hat = model.predict(X_val)
random.shuffle(Y_hat)
print '\t random (permutations): %s' % accuracy(Y_hat, Y_val)
















